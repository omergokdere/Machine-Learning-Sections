{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.64331076301565\n",
      "141.1939643992886\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    " \n",
    " \n",
    "class GeoLocation:\n",
    "    '''\n",
    "    Class representing a coordinate on a sphere, most likely Earth.\n",
    "    \n",
    "    This class is based from the code smaple in this paper:\n",
    "        http://janmatuschek.de/LatitudeLongitudeBoundingCoordinates\n",
    "        \n",
    "    The owner of that website, Jan Philip Matuschek, is the full owner of \n",
    "    his intellectual property. This class is simply a Python port of his very\n",
    "    useful Java code. All code written by Jan Philip Matuschek and ported by me \n",
    "    (which is all of this class) is owned by Jan Philip Matuschek.\n",
    "    '''\n",
    " \n",
    " \n",
    "    MIN_LAT = math.radians(-90)\n",
    "    MAX_LAT = math.radians(90)\n",
    "    MIN_LON = math.radians(-180)\n",
    "    MAX_LON = math.radians(180)\n",
    "    \n",
    "    EARTH_RADIUS = 6378.1  # kilometers\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def from_degrees(cls, deg_lat, deg_lon):\n",
    "        rad_lat = math.radians(deg_lat)\n",
    "        rad_lon = math.radians(deg_lon)\n",
    "        return GeoLocation(rad_lat, rad_lon, deg_lat, deg_lon)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_radians(cls, rad_lat, rad_lon):\n",
    "        deg_lat = math.degrees(rad_lat)\n",
    "        deg_lon = math.degrees(rad_lon)\n",
    "        return GeoLocation(rad_lat, rad_lon, deg_lat, deg_lon)\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            rad_lat,\n",
    "            rad_lon,\n",
    "            deg_lat,\n",
    "            deg_lon\n",
    "    ):\n",
    "        self.rad_lat = float(rad_lat)\n",
    "        self.rad_lon = float(rad_lon)\n",
    "        self.deg_lat = float(deg_lat)\n",
    "        self.deg_lon = float(deg_lon)\n",
    "        self._check_bounds()\n",
    "        \n",
    "    def __str__(self):\n",
    "        degree_sign= u'\\N{DEGREE SIGN}'\n",
    "        return (\"({0:.4f}deg, {1:.4f}deg) = ({2:.6f}rad, {3:.6f}rad)\").format(\n",
    "            self.deg_lat, self.deg_lon, self.rad_lat, self.rad_lon)\n",
    "        \n",
    "    def _check_bounds(self):\n",
    "        if (self.rad_lat < GeoLocation.MIN_LAT \n",
    "                or self.rad_lat > GeoLocation.MAX_LAT \n",
    "                or self.rad_lon < GeoLocation.MIN_LON \n",
    "                or self.rad_lon > GeoLocation.MAX_LON):\n",
    "            raise Exception(\"Illegal arguments\")\n",
    "            \n",
    "    def distance_to(self, other, radius=EARTH_RADIUS):\n",
    "        '''\n",
    "        Computes the great circle distance between this GeoLocation instance\n",
    "        and the other.\n",
    "        '''\n",
    "        return radius * math.acos(\n",
    "                math.sin(self.rad_lat) * math.sin(other.rad_lat) +\n",
    "                math.cos(self.rad_lat) * \n",
    "                math.cos(other.rad_lat) * \n",
    "                math.cos(self.rad_lon - other.rad_lon)\n",
    "            )\n",
    "            \n",
    "    def bounding_locations(self, distance, radius=EARTH_RADIUS):\n",
    "        '''\n",
    "        Computes the bounding coordinates of all points on the surface\n",
    "        of a sphere that has a great circle distance to the point represented\n",
    "        by this GeoLocation instance that is less or equal to the distance argument.\n",
    "        \n",
    "        Param:\n",
    "            distance - the distance from the point represented by this GeoLocation\n",
    "                       instance. Must be measured in the same unit as the radius\n",
    "                       argument (which is kilometers by default)\n",
    "            \n",
    "            radius   - the radius of the sphere. defaults to Earth's radius.\n",
    "            \n",
    "        Returns a list of two GeoLoations - the SW corner and the NE corner - that\n",
    "        represents the bounding box.\n",
    "        '''\n",
    "        \n",
    "        if radius < 0 or distance < 0:\n",
    "            raise Exception(\"Illegal arguments\")\n",
    "            \n",
    "        # angular distance in radians on a great circle\n",
    "        rad_dist = distance / radius\n",
    "        \n",
    "        min_lat = self.rad_lat - rad_dist\n",
    "        max_lat = self.rad_lat + rad_dist\n",
    "        \n",
    "        if min_lat > GeoLocation.MIN_LAT and max_lat < GeoLocation.MAX_LAT:\n",
    "            delta_lon = math.asin(math.sin(rad_dist) / math.cos(self.rad_lat))\n",
    "            \n",
    "            min_lon = self.rad_lon - delta_lon\n",
    "            if min_lon < GeoLocation.MIN_LON:\n",
    "                min_lon += 2 * math.pi\n",
    "                \n",
    "            max_lon = self.rad_lon + delta_lon\n",
    "            if max_lon > GeoLocation.MAX_LON:\n",
    "                max_lon -= 2 * math.pi\n",
    "        # a pole is within the distance\n",
    "        else:\n",
    "            min_lat = max(min_lat, GeoLocation.MIN_LAT)\n",
    "            max_lat = min(max_lat, GeoLocation.MAX_LAT)\n",
    "            min_lon = GeoLocation.MIN_LON\n",
    "            max_lon = GeoLocation.MAX_LON\n",
    "        \n",
    "        return [ GeoLocation.from_radians(min_lat, min_lon) , \n",
    "            GeoLocation.from_radians(max_lat, max_lon) ]\n",
    "\n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    " \n",
    "    # Test bounding box\n",
    "    loc = GeoLocation.from_degrees(22.0622221, -81.222253)\n",
    "    distance = 100  # 1 kilometer\n",
    "    SW_loc, NE_loc = loc.bounding_locations(distance)\n",
    "    print (loc.distance_to(SW_loc))\n",
    "    print (loc.distance_to(NE_loc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project\n",
    "\n",
    "Welcome to the NLP Project for this section of the course. In this NLP project you will be attempting to classify Yelp Reviews into 1 star or 5 star categories based off the text content in the reviews. This will be a simpler procedure than the lecture, since we will utilize the pipeline methods for more complex tasks.\n",
    "\n",
    "We will use the [Yelp Review Data Set from Kaggle](https://www.kaggle.com/c/yelp-recsys-2013).\n",
    "\n",
    "Each observation in this dataset is a review of a particular business by a particular user.\n",
    "\n",
    "The \"stars\" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "\n",
    "The \"cool\" column is the number of \"cool\" votes this review received from other Yelp users. \n",
    "\n",
    "All reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n",
    "\n",
    "The \"useful\" and \"funny\" columns are similar to the \"cool\" column.\n",
    "\n",
    "Let's get started! Just follow the directions below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    " **Import the usual suspects. :) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**Read the yelp.csv file and set it as a dataframe called yelp.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "8\n",
    "import dask.dataframe as dd\n",
    " \n",
    "filename = '311_Service_Requests.csv'\n",
    "df = dd.read_csv(filename, dtype='str')\n",
    "yelp = pd.read_csv('/Users/Faheem/Desktop/yelp.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the head, info , and describe methods on yelp.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_text</th>\n",
       "      <th>positive_review_counter_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>2</td>\n",
       "      <td>The pizza was okay. Not the best I've had. I p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elqbBhBfElMNSrjFqW3now</td>\n",
       "      <td>2</td>\n",
       "      <td>Back in 2005-2007 this place was my FAVORITE t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  \\\n",
       "0  iCQpiavjjPzJ5_3gPD5Ebg      2   \n",
       "1  pomGBqfbxcqPv14c3XH-ZQ      5   \n",
       "2  jtQARsP6P-LbkyjbO1qNGg      1   \n",
       "3  elqbBhBfElMNSrjFqW3now      2   \n",
       "4  Ums3gaP2qM3W1XcA5r6SsQ      5   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  The pizza was okay. Not the best I've had. I p...   \n",
       "1  I love this place! My fiance And I go here atl...   \n",
       "2  Terrible. Dry corn bread. Rib tips were all fa...   \n",
       "3  Back in 2005-2007 this place was my FAVORITE t...   \n",
       "4  Delicious healthy food. The steak is amazing. ...   \n",
       "\n",
       "   positive_review_counter_business  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3658019 entries, 0 to 3658018\n",
      "Data columns (total 4 columns):\n",
      "business_id                         object\n",
      "stars                               int64\n",
      "review_text                         object\n",
      "positive_review_counter_business    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 111.6+ MB\n"
     ]
    }
   ],
   "source": [
    "yelp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>positive_review_counter_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.658019e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.714371e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.365544e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              stars  positive_review_counter_business\n",
       "count  3.658019e+06                               0.0\n",
       "mean   3.714371e+00                               NaN\n",
       "std    1.365544e+00                               NaN\n",
       "min    0.000000e+00                               NaN\n",
       "25%    3.000000e+00                               NaN\n",
       "50%    4.000000e+00                               NaN\n",
       "75%    5.000000e+00                               NaN\n",
       "max    5.000000e+00                               NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Let's explore the data\n",
    "\n",
    "## Imports\n",
    "\n",
    "**Import the data visualization libraries if you haven't done so already.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1729d602550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='stars',data=yelp,palette='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use groupby to get the mean values of the numerical columns, you should be able to create this dataframe with the operation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_review_counter_business</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       positive_review_counter_business\n",
       "stars                                  \n",
       "0                                   NaN\n",
       "1                                   NaN\n",
       "2                                   NaN\n",
       "3                                   NaN\n",
       "4                                   NaN\n",
       "5                                   NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = yelp.groupby('stars').mean()\n",
    "stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the corr() method on that groupby dataframe to produce this dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_review_counter_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_review_counter_business</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  positive_review_counter_business\n",
       "positive_review_counter_business                               NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then use seaborn to create a heatmap based off that .corr() dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-71c3b8202a20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coolwarm'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    516\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                           yticklabels, mask)\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[1;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;31m# Determine good default values for the colormapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[1;32m--> 168\u001b[1;33m                                     cmap, center, robust)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# Sort out the annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mcalc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mvmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrobust\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcalc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m98\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrobust\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcalc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "sns.heatmap(stars.corr(),cmap='coolwarm',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Classification Task\n",
    "\n",
    "Let's move on to the actual task. To make things a little easier, go ahead and only grab reviews that were either 1 star or 5 stars.\n",
    "\n",
    "**Create a dataframe called yelp_class that contains the columns of yelp dataframe but for only the 1 or 5 star reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_class = yelp[(yelp.stars==1) | (yelp.stars==5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create two objects X and y. X will be the 'text' column of yelp_class and y will be the 'stars' column of yelp_class. (Your features and target/labels)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_class['review_text']\n",
    "y = yelp_class['stars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import CountVectorizer and create a CountVectorizer object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use the fit_transform method on the CountVectorizer object and pass in X (the 'text' column). Save this result by overwriting X.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Let's split our data into training and testing data.\n",
    "\n",
    "** Use train_test_split to split up the data into X_train, X_test, y_train, y_test. Use test_size=0.3 and random_state=101 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "Time to train a model!\n",
    "\n",
    "** Import MultinomialNB and create an instance of the estimator and call is nb **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now fit nb using the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluations\n",
    "\n",
    "Time to see how our model did!\n",
    "\n",
    "**Use the predict method off of nb to predict labels from X_test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a confusion matrix and classification report using these predictions and y_test **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118140   9443]\n",
      " [ 12079 413022]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.91      0.93      0.92    127583\n",
      "          5       0.98      0.97      0.97    425101\n",
      "\n",
      "avg / total       0.96      0.96      0.96    552684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! Let's see what happens if we try to include TF-IDF to this process using a pipeline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Text Processing\n",
    "\n",
    "** Import TfidfTransformer from sklearn. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Pipeline from sklearn. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create a pipeline with the following steps:CountVectorizer(), TfidfTransformer(),MultinomialNB()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Pipeline\n",
    "\n",
    "**Time to use the pipeline! Remember this pipeline has all your pre-process steps in it already, meaning we'll need to re-split the original data (Remember that we overwrote X as the CountVectorized version. What we need is just the text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "**Redo the train test split on the yelp_class object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_class['review_text']\n",
    "y = yelp_class['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now fit the pipeline to the training data. Remember you can't use the same training data as last time because that data has already been vectorized. We need to pass in just the text and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May take some time\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Evaluation\n",
    "\n",
    "** Now use the pipeline to predict from the X_test and create a classification report and confusion matrix. You should notice strange results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101759  25824]\n",
      " [  3035 422066]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      0.80      0.88    127583\n",
      "          5       0.94      0.99      0.97    425101\n",
      "\n",
      "avg / total       0.95      0.95      0.95    552684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Tf-Idf actually made things worse! That is it for this project. But there is still a lot more you can play with:\n",
    "\n",
    "**Some other things to try....**\n",
    "Try going back and playing around with the pipeline steps and seeing if creating a custom analyzer like we did in the lecture helps (note: it probably won't). Or recreate the pipeline with just the CountVectorizer() and NaiveBayes. Does changing the ML model at the end to another classifier help at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
